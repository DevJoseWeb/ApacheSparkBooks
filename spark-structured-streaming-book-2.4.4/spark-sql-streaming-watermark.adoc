== Streaming Watermark

*Streaming Watermark* (*Event-Time Watermark*) of a <<spark-sql-streaming-stateful-stream-processing.adoc#, stateful streaming query>> is a *time threshold* to wait for late and possibly out-of-order events until a streaming state can be considered final.

Streaming watermark is used to mark events that are older than the threshold as "too late", and not "interesting" to update partial non-final aggregates.

The *event-time watermark delay* is used to calculate the difference between the event time of an event (modeled as a row in the streaming Dataset) and the time in the past.

With streaming watermark, memory usage of a streaming state can be controlled as late events can easily be dropped, and old aggregates that are never going to be updated removed. That avoids unbounded streaming state that would inevitably use up all the available memory of long-running streaming queries and end up in out of memory errors.

In Spark Structured Streaming, you use <<spark-sql-streaming-Dataset-operators.adoc#withWatermark, Dataset.withWatermark>> high-level operator to define a streaming watermark.

A streaming watermark has to be defined on one or many grouping expressions of a streaming aggregation (directly or using <<spark-sql-streaming-window.adoc#, window>> standard function).

NOTE: <<spark-sql-streaming-Dataset-operators.adoc#withWatermark, Dataset.withWatermark>> operator has to be used before an aggregation operator (for the watermark to have an effect).

In <<spark-sql-streaming-OutputMode.adoc#Append, Append>> output mode the current event-time streaming watermark is used for the following:

* Output saved state rows that became expired (*Expired events* in the demo)

* Dropping late events, i.e. don't save them to a state store or include in aggregation (*Late events* in the demo)

Streaming watermark is <<spark-sql-streaming-UnsupportedOperationChecker.adoc#streaming-aggregation-append-mode-requires-watermark, required>> for a <<spark-sql-streaming-aggregation.adoc#, streaming aggregation>> in <<spark-sql-streaming-OutputMode.adoc#Append, append>> output mode.

*Watermark delay* says how late and possibly out-of-order events are still acceptable and contribute to the final result of a stateful streaming query.

=== [[demos]] Demos

Use the following demos to learn more:

* <<spark-sql-streaming-demo-watermark-aggregation-append.adoc#, Demo: Streaming Watermark with Aggregation in Append Output Mode>>

=== [[internals]] Internals

Under the covers, <<spark-sql-streaming-Dataset-operators.adoc#withWatermark, Dataset.withWatermark>> high-level operator creates a logical query plan with <<spark-sql-streaming-EventTimeWatermark.adoc#, EventTimeWatermark>> logical operator.

`EventTimeWatermark` logical operator is planned to <<spark-sql-streaming-EventTimeWatermarkExec.adoc#, EventTimeWatermarkExec>> physical operator that extracts the event times (from the data being processed) and adds them to an accumulator.

Since the execution (data processing) happens on Spark executors, using the accumulator is the only _Spark-approved way_ for communication between the tasks (on the executors) and the driver. Using accumulator updates the driver with the current event-time watermark.

During the query planning phase (in <<spark-sql-streaming-MicroBatchExecution.adoc#runBatch-queryPlanning, MicroBatchExecution>> and <<spark-sql-streaming-ContinuousExecution.adoc#runContinuous-queryPlanning, ContinuousExecution>>) that also happens on the driver, `IncrementalExecution` is given the current <<spark-sql-streaming-OffsetSeqMetadata.adoc#, OffsetSeqMetadata>> with the current event-time watermark.

=== [[i-want-more]] Further Reading Or Watching

* https://issues.apache.org/jira/browse/SPARK-18124[SPARK-18124 Observed delay based event time watermarks]
