== [[RelationProvider]] RelationProvider Contract -- Relation Providers With Schema Inference

`RelationProvider` is the <<contract, contract>> of <<implementations, BaseRelation providers>> that <<createRelation, create a relation with schema inference>>.

NOTE: *Schema inference* is also called *schema discovery*.

The requirement of not specifying a user-defined schema or having one that does not match the relation is enforced when `DataSource` is requested for a <<spark-sql-DataSource.adoc#resolveRelation, BaseRelation>> for a given data source format. If specified and does not match, `DataSource` throws a `AnalysisException`:

```
[className] does not allow user-specified schemas.
```

[[contract]]
[source, scala]
----
package org.apache.spark.sql.sources

trait RelationProvider {
  def createRelation(
    sqlContext: SQLContext,
    parameters: Map[String, String]): BaseRelation
}
----

.RelationProvider Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| `createRelation`
| [[createRelation]] Creates a <<spark-sql-BaseRelation.adoc#, BaseRelation>> for loading data from an external data source

Used exclusively when `DataSource` is requested for a <<spark-sql-DataSource.adoc#resolveRelation, BaseRelation>> for a given data source format (and no user-defined schema or the user-defined schema matches <<spark-sql-BaseRelation.adoc#schema, schema>> of the `BaseRelation`)
|===

[[implementations]]
.RelationProviders
[width="100%",cols="1,2",options="header"]
|===
| RelationProvider
| Description

| link:spark-sql-JdbcRelationProvider.adoc[JdbcRelationProvider]
| [[JdbcRelationProvider]]

| link:spark-sql-KafkaSourceProvider.adoc[KafkaSourceProvider]
| [[KafkaSourceProvider]]
|===

TIP: Use link:spark-sql-SchemaRelationProvider.adoc[SchemaRelationProvider] for relation providers that require a user-defined schema.
