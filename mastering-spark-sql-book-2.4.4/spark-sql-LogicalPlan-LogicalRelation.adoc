== [[LogicalRelation]] LogicalRelation Leaf Logical Operator -- Representing BaseRelations in Logical Plan

`LogicalRelation` is a link:spark-sql-LogicalPlan-LeafNode.adoc[leaf logical operator] that represents a <<relation, BaseRelation>> in a link:spark-sql-LogicalPlan.adoc[logical query plan].

[source, scala]
----
val q1 = spark.read.option("header", true).csv("../datasets/people.csv")
scala> println(q1.queryExecution.logical.numberedTreeString)
00 Relation[id#72,name#73,age#74] csv

val q2 = sql("select * from `csv`.`../datasets/people.csv`")
scala> println(q2.queryExecution.optimizedPlan.numberedTreeString)
00 Relation[_c0#175,_c1#176,_c2#177] csv
----

`LogicalRelation` is <<creating-instance, created>> when:

* `DataFrameReader` link:spark-sql-DataFrameReader.adoc#load[loads data from a data source that supports multiple paths] (through link:spark-sql-SparkSession.adoc#baseRelationToDataFrame[SparkSession.baseRelationToDataFrame])
* `DataFrameReader` is requested to load data from an external table using link:spark-sql-DataFrameReader.adoc#jdbc[JDBC] (through link:spark-sql-SparkSession.adoc#baseRelationToDataFrame[SparkSession.baseRelationToDataFrame])
* `TextInputCSVDataSource` and `TextInputJsonDataSource` are requested to infer schema
* `ResolveSQLOnFile` converts a logical plan
* `FindDataSourceTable` logical evaluation rule is link:spark-sql-Analyzer-FindDataSourceTable.adoc#apply[executed]
* `RelationConversions` logical evaluation rule is link:spark-sql-Analyzer-RelationConversions.adoc#apply[executed]
* `CreateTempViewUsing` logical command is requested to <<spark-sql-LogicalPlan-CreateTempViewUsing.adoc#run, run>>
* Structured Streaming's `FileStreamSource` creates batches of records

[[apply]]
[NOTE]
====
`LogicalRelation` can be created using `apply` factory methods that accept <<relation, BaseRelation>> with optional <<catalogTable, CatalogTable>>.

[source, scala]
----
apply(relation: BaseRelation): LogicalRelation
apply(relation: BaseRelation, table: CatalogTable): LogicalRelation
----
====

[[simpleString]]
The link:spark-sql-catalyst-QueryPlan.adoc#simpleString[simple text representation] of a `LogicalRelation` (aka `simpleString`) is *Relation[output] [relation]* (that uses the <<output, output>> and <<relation, BaseRelation>>).

[source, scala]
----
val q = spark.read.text("README.md")
val logicalPlan = q.queryExecution.logical
scala> println(logicalPlan.simpleString)
Relation[value#2] text
----

=== [[refresh]] `refresh` Method

[source, scala]
----
refresh(): Unit
----

NOTE: `refresh` is part of link:spark-sql-LogicalPlan.adoc#refresh[LogicalPlan Contract] to refresh itself.

`refresh` requests the link:spark-sql-BaseRelation-HadoopFsRelation.adoc#location[FileIndex] of a `HadoopFsRelation` <<relation, relation>> to refresh.

NOTE: `refresh` does the work for link:spark-sql-BaseRelation-HadoopFsRelation.adoc[HadoopFsRelation] relations only.

=== [[creating-instance]] Creating LogicalRelation Instance

`LogicalRelation` takes the following when created:

* [[relation]] link:spark-sql-BaseRelation.adoc[BaseRelation]
* [[output]] Output schema `AttributeReferences`
* [[catalogTable]] Optional link:spark-sql-CatalogTable.adoc[CatalogTable]
